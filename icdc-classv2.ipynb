{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ben     1700 non-null   object\n",
      " 1   guj     1700 non-null   object\n",
      " 2   hin     1700 non-null   object\n",
      " 3   kan     1700 non-null   object\n",
      " 4   mal     1700 non-null   object\n",
      " 5   ori     1700 non-null   object\n",
      " 6   pan     1700 non-null   object\n",
      " 7   tam     1700 non-null   object\n",
      " 8   tel     1700 non-null   object\n",
      " 9   urd     1700 non-null   object\n",
      " 10  eng     1700 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('icdc\\\\train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:01<00:00, 1632.05it/s]\n"
     ]
    }
   ],
   "source": [
    "allTexts = ''\n",
    "for i in tqdm(range(df.__len__())):\n",
    "    allTexts += ''.join(df.iloc[i]).lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace('-', '').replace('*', '').replace('^', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglish_res = Counter(allTexts)\n",
    "# sorted(list(dict(hinglish_res).items()), key = lambda x: x[1], reverse=True)\n",
    "charsVocab = list(dict(hinglish_res).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_NULL = '-'\n",
    "PAD_START = '*'\n",
    "PAD_END = '^'\n",
    "\n",
    "vocab = [PAD_NULL, PAD_START, PAD_END]+[i[0] for i in charsVocab]\n",
    "\n",
    "IDX_PAD_NULL = vocab.index(PAD_NULL)\n",
    "\n",
    "len(vocab), IDX_PAD_NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau#, StepLR, ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1],\n",
       "        [14, 19],\n",
       "        [ 4, 13],\n",
       "        [ 4, 17],\n",
       "        [12,  3],\n",
       "        [ 0, 36],\n",
       "        [ 0, 36],\n",
       "        [ 0, 36],\n",
       "        [ 0, 14]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_extraToken(texts, startToken=True, endToken=True):\n",
    "    if startToken and endToken: return [PAD_START+text+PAD_END for text in texts]\n",
    "    elif startToken: return [PAD_START+text for text in texts]\n",
    "    elif endToken: return [text+PAD_END for text in texts]\n",
    "    else: return texts\n",
    "\n",
    "def remove_extraToken(texts:list[str])->list[str]:\n",
    "    return [text.lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace(PAD_START, '').replace(PAD_END, '').replace(PAD_NULL, '')\n",
    "            for text in texts]\n",
    "\n",
    "def preprocesser(texts: list[str], prePadding=False, startToken=True, endToken=True, batch_first=False):\n",
    "    texts = add_extraToken(remove_extraToken(texts), startToken, endToken)\n",
    "    text_ints = [[vocab.index(c) for c in text if c in vocab] for text in texts]\n",
    "    # Apply pre-padding to each sequence\n",
    "    if prePadding:\n",
    "        max_length = max(len(seq) for seq in text_ints)\n",
    "        padded_seqs = pad_sequence([torch.cat([torch.tensor([IDX_PAD_NULL]*(max_length - len(seq)), dtype=torch.int64), torch.LongTensor(seq)]) for seq in text_ints], batch_first=True)\n",
    "    else:\n",
    "        padded_seqs = pad_sequence([torch.LongTensor(seq) for seq in text_ints], batch_first=True, padding_value=IDX_PAD_NULL)\n",
    "    \n",
    "    return padded_seqs if batch_first else padded_seqs.T\n",
    "\n",
    "\n",
    "preprocesser(['hiir', 'laksfffh'], startToken=True, endToken=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, batch_size=64):\n",
    "        dataset = []\n",
    "\n",
    "        for y, col in enumerate(df.columns):\n",
    "            for i in range(df[col].__len__()):\n",
    "                text = df[col].iloc[i].lower().replace('–','').replace('$','').replace('&','').replace('[','').replace(']',''\n",
    "                                            ).replace('“','').replace('”','').replace('=','').replace('৷','').replace('`','').replace('ؑ', '').replace('}',''\n",
    "                                            ).replace(PAD_START, '').replace(PAD_END, '').replace(PAD_NULL, '')\n",
    "                dataset.append((text, y, df[col].iloc[i]))\n",
    "        \n",
    "        dataset.sort(key=lambda x: len(x[0]))\n",
    "        \n",
    "        self.batched = []\n",
    "        for i in range(0, len(dataset), batch_size): self.batched.append(self.custom_collate_fn(dataset[i:i+batch_size]))\n",
    "    \n",
    "    def custom_collate_fn(self, batch):\n",
    "        x = []\n",
    "        y = []\n",
    "        real = []\n",
    "        for ix, iy, ireal in batch:\n",
    "            x.append(ix)\n",
    "            y.append(iy)\n",
    "            real.append(ireal)\n",
    "        return preprocesser(x), F.one_hot(torch.tensor(y), num_classes=11).to(torch.float32), real\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batched)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single sequence and its label\n",
    "        return self.batched[idx]\n",
    "\n",
    "# Create a DataLoader with batch size 64\n",
    "custom_dataset = CustomDataset(batch_size=64)  # Create an instance of the custom dataset\n",
    "data_loader = DataLoader(custom_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader:\n",
    "    sequences, labels, _ = batch\n",
    "    sequences.squeeze_(0)\n",
    "    labels.squeeze_(0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, num_layers, vocab_size, p=0, num_classes=11):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=p, bidirectional=False) \n",
    "        # self.fc1 = nn.Linear(hidden_size, hidden_size*2)\n",
    "        # self.fc2 = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (sequencen x batch_size)\n",
    "        x = self.dropout(self.embedding(x)) # (sequencen x batch_size x embedding_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(x) # (sequencen x batch_size x hidden_size), ((num_layers x batch_size x hidden_size), (num_layers x batch_size x hidden_size))\n",
    "        return self.fc(outputs[-1])\n",
    "        # x = F.relu(self.fc1(outputs[-1]))\n",
    "        # return self.fc2(x)\n",
    "\n",
    "\n",
    "# Create an LSTM model\n",
    "# model = Encoder(50, 128, 2, vocab_size=len(vocab)).to(DEVICE)\n",
    "# x = sequences\n",
    "# y = labels\n",
    "# print(x.shape)\n",
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "LR = 0.001\n",
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "P = 0.5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "TRAIN_SIZE = .8\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def accuracy(model, data_loader):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Disable gradient computation during inference\n",
    "    for (sequences, labels, _) in data_loader: # test_loader\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE).argmax(dim=1)\n",
    "        # Forward pass\n",
    "        predicted = model(sequences).argmax(dim=1)\n",
    "            \n",
    "        # Count total number of labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Count number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    model.train()\n",
    "    # Calculate accuracy\n",
    "    return 100 * correct / total\n",
    "    # print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader with batch size 64\n",
    "custom_dataset = CustomDataset(BATCH_SIZE)\n",
    "\n",
    "train_size = int(0.8 * len(custom_dataset))\n",
    "test_size = len(custom_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Encoder(EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, vocab_size=len(vocab), p=P, num_classes=11).to(device=DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model.load_state_dict(torch.load('models_icdc\\\\gru.model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 3s] Train Epoch: [0/100] \tLoss: 418.15 Test Loss: 307.27\n",
      "[0m 5s] Train Epoch: [1/100] \tLoss: 273.46 Test Loss: 212.90\n",
      "[0m 7s] Train Epoch: [2/100] \tLoss: 230.30 Test Loss: 184.81\n",
      "[0m 9s] Train Epoch: [3/100] \tLoss: 196.22 Test Loss: 153.47\n",
      "[0m 11s] Train Epoch: [4/100] \tLoss: 166.34 Test Loss: 123.70\n",
      "[0m 13s] Train Epoch: [5/100] \tLoss: 149.79 Test Loss: 113.85\n",
      "[0m 15s] Train Epoch: [6/100] \tLoss: 133.85 Test Loss: 101.53\n",
      "[0m 16s] Train Epoch: [7/100] \tLoss: 122.61 Test Loss: 92.15\n",
      "[0m 18s] Train Epoch: [8/100] \tLoss: 110.83 Test Loss: 90.33\n",
      "[0m 20s] Train Epoch: [9/100] \tLoss: 104.45 Test Loss: 77.36\n",
      "[0m 21s] Train Epoch: [10/100] \tLoss: 94.91 Test Loss: 72.82\n",
      "[0m 23s] Train Epoch: [11/100] \tLoss: 87.04 Test Loss: 72.14\n",
      "[0m 25s] Train Epoch: [12/100] \tLoss: 77.93 Test Loss: 62.44\n",
      "[0m 26s] Train Epoch: [13/100] \tLoss: 74.27 Test Loss: 67.58\n",
      "[0m 28s] Train Epoch: [14/100] \tLoss: 69.72 Test Loss: 60.27\n",
      "[0m 30s] Train Epoch: [15/100] \tLoss: 64.76 Test Loss: 58.71\n",
      "[0m 31s] Train Epoch: [16/100] \tLoss: 59.94 Test Loss: 48.88\n",
      "[0m 33s] Train Epoch: [17/100] \tLoss: 53.89 Test Loss: 46.35\n",
      "[0m 35s] Train Epoch: [18/100] \tLoss: 52.28 Test Loss: 44.56\n",
      "[0m 36s] Train Epoch: [19/100] \tLoss: 48.38 Test Loss: 41.75\n",
      "[0m 38s] Train Epoch: [20/100] \tLoss: 45.74 Test Loss: 41.33\n",
      "[0m 40s] Train Epoch: [21/100] \tLoss: 41.06 Test Loss: 39.91\n",
      "[0m 41s] Train Epoch: [22/100] \tLoss: 42.26 Test Loss: 38.53\n",
      "[0m 43s] Train Epoch: [23/100] \tLoss: 38.03 Test Loss: 39.95\n",
      "[0m 45s] Train Epoch: [24/100] \tLoss: 35.48 Test Loss: 40.39\n",
      "[0m 47s] Train Epoch: [25/100] \tLoss: 32.87 Test Loss: 39.01\n",
      "[0m 48s] Train Epoch: [26/100] \tLoss: 31.23 Test Loss: 36.37\n",
      "[0m 50s] Train Epoch: [27/100] \tLoss: 33.66 Test Loss: 38.69\n",
      "[0m 52s] Train Epoch: [28/100] \tLoss: 29.40 Test Loss: 35.27\n",
      "[0m 53s] Train Epoch: [29/100] \tLoss: 27.39 Test Loss: 36.76\n",
      "[0m 55s] Train Epoch: [30/100] \tLoss: 27.49 Test Loss: 38.54\n",
      "[0m 57s] Train Epoch: [31/100] \tLoss: 25.34 Test Loss: 33.94\n",
      "[0m 59s] Train Epoch: [32/100] \tLoss: 24.66 Test Loss: 35.13\n",
      "[1m 0s] Train Epoch: [33/100] \tLoss: 25.04 Test Loss: 32.64\n",
      "[1m 2s] Train Epoch: [34/100] \tLoss: 23.00 Test Loss: 34.48\n",
      "[1m 4s] Train Epoch: [35/100] \tLoss: 22.41 Test Loss: 36.07\n",
      "[1m 6s] Train Epoch: [36/100] \tLoss: 19.85 Test Loss: 36.32\n",
      "[1m 7s] Train Epoch: [37/100] \tLoss: 18.85 Test Loss: 36.03\n",
      "[1m 9s] Train Epoch: [38/100] \tLoss: 17.69 Test Loss: 32.80\n",
      "[1m 10s] Train Epoch: [39/100] \tLoss: 18.23 Test Loss: 33.65\n",
      "[1m 12s] Train Epoch: [40/100] \tLoss: 16.96 Test Loss: 31.68\n",
      "[1m 14s] Train Epoch: [41/100] \tLoss: 17.24 Test Loss: 34.90\n",
      "[1m 15s] Train Epoch: [42/100] \tLoss: 16.54 Test Loss: 31.02\n",
      "[1m 17s] Train Epoch: [43/100] \tLoss: 15.21 Test Loss: 33.64\n",
      "[1m 18s] Train Epoch: [44/100] \tLoss: 15.89 Test Loss: 35.25\n",
      "[1m 20s] Train Epoch: [45/100] \tLoss: 16.67 Test Loss: 34.15\n",
      "[1m 22s] Train Epoch: [46/100] \tLoss: 17.03 Test Loss: 35.39\n",
      "[1m 23s] Train Epoch: [47/100] \tLoss: 14.63 Test Loss: 35.57\n",
      "[1m 25s] Train Epoch: [48/100] \tLoss: 14.12 Test Loss: 34.45\n",
      "[1m 27s] Train Epoch: [49/100] \tLoss: 13.35 Test Loss: 30.13\n",
      "[1m 28s] Train Epoch: [50/100] \tLoss: 12.62 Test Loss: 31.32\n",
      "[1m 30s] Train Epoch: [51/100] \tLoss: 12.29 Test Loss: 31.43\n",
      "[1m 32s] Train Epoch: [52/100] \tLoss: 11.41 Test Loss: 30.58\n",
      "[1m 33s] Train Epoch: [53/100] \tLoss: 11.17 Test Loss: 32.23\n",
      "[1m 35s] Train Epoch: [54/100] \tLoss: 11.34 Test Loss: 33.23\n",
      "[1m 36s] Train Epoch: [55/100] \tLoss: 12.01 Test Loss: 35.67\n",
      "[1m 38s] Train Epoch: [56/100] \tLoss: 11.50 Test Loss: 32.37\n",
      "[1m 40s] Train Epoch: [57/100] \tLoss: 11.27 Test Loss: 35.10\n",
      "[1m 42s] Train Epoch: [58/100] \tLoss: 10.76 Test Loss: 33.74\n",
      "[1m 43s] Train Epoch: [59/100] \tLoss: 9.95 Test Loss: 33.26\n",
      "[1m 45s] Train Epoch: [60/100] \tLoss: 8.81 Test Loss: 34.19\n",
      "[1m 47s] Train Epoch: [61/100] \tLoss: 6.77 Test Loss: 32.65\n",
      "[1m 49s] Train Epoch: [62/100] \tLoss: 6.77 Test Loss: 31.49\n",
      "[1m 50s] Train Epoch: [63/100] \tLoss: 6.46 Test Loss: 31.88\n",
      "[1m 52s] Train Epoch: [64/100] \tLoss: 6.36 Test Loss: 31.10\n",
      "[1m 54s] Train Epoch: [65/100] \tLoss: 6.41 Test Loss: 31.17\n",
      "[1m 56s] Train Epoch: [66/100] \tLoss: 5.89 Test Loss: 31.27\n",
      "[1m 57s] Train Epoch: [67/100] \tLoss: 5.76 Test Loss: 31.46\n",
      "[1m 59s] Train Epoch: [68/100] \tLoss: 5.35 Test Loss: 31.30\n",
      "[2m 1s] Train Epoch: [69/100] \tLoss: 5.67 Test Loss: 31.49\n",
      "[2m 3s] Train Epoch: [70/100] \tLoss: 5.24 Test Loss: 30.66\n",
      "[2m 4s] Train Epoch: [71/100] \tLoss: 5.77 Test Loss: 30.25\n",
      "[2m 6s] Train Epoch: [72/100] \tLoss: 6.19 Test Loss: 30.19\n",
      "[2m 8s] Train Epoch: [73/100] \tLoss: 5.11 Test Loss: 30.34\n",
      "[2m 10s] Train Epoch: [74/100] \tLoss: 4.76 Test Loss: 30.31\n",
      "[2m 12s] Train Epoch: [75/100] \tLoss: 5.23 Test Loss: 30.26\n",
      "[2m 14s] Train Epoch: [76/100] \tLoss: 5.00 Test Loss: 30.30\n",
      "[2m 15s] Train Epoch: [77/100] \tLoss: 4.74 Test Loss: 30.41\n",
      "[2m 17s] Train Epoch: [78/100] \tLoss: 4.76 Test Loss: 30.39\n",
      "[2m 19s] Train Epoch: [79/100] \tLoss: 4.87 Test Loss: 30.39\n",
      "[2m 21s] Train Epoch: [80/100] \tLoss: 4.34 Test Loss: 30.37\n",
      "[2m 23s] Train Epoch: [81/100] \tLoss: 4.57 Test Loss: 30.41\n",
      "[2m 24s] Train Epoch: [82/100] \tLoss: 5.35 Test Loss: 30.30\n",
      "[2m 26s] Train Epoch: [83/100] \tLoss: 4.90 Test Loss: 30.31\n",
      "[2m 28s] Train Epoch: [84/100] \tLoss: 4.34 Test Loss: 30.32\n",
      "[2m 30s] Train Epoch: [85/100] \tLoss: 5.05 Test Loss: 30.32\n",
      "[2m 32s] Train Epoch: [86/100] \tLoss: 4.84 Test Loss: 30.33\n",
      "[2m 34s] Train Epoch: [87/100] \tLoss: 5.00 Test Loss: 30.32\n",
      "[2m 35s] Train Epoch: [88/100] \tLoss: 5.43 Test Loss: 30.31\n",
      "[2m 37s] Train Epoch: [89/100] \tLoss: 4.64 Test Loss: 30.31\n",
      "[2m 39s] Train Epoch: [90/100] \tLoss: 4.61 Test Loss: 30.33\n",
      "[2m 41s] Train Epoch: [91/100] \tLoss: 4.83 Test Loss: 30.33\n",
      "[2m 42s] Train Epoch: [92/100] \tLoss: 4.89 Test Loss: 30.33\n",
      "[2m 44s] Train Epoch: [93/100] \tLoss: 4.77 Test Loss: 30.33\n",
      "[2m 46s] Train Epoch: [94/100] \tLoss: 4.97 Test Loss: 30.33\n",
      "[2m 47s] Train Epoch: [95/100] \tLoss: 4.64 Test Loss: 30.33\n",
      "[2m 49s] Train Epoch: [96/100] \tLoss: 4.95 Test Loss: 30.33\n",
      "[2m 51s] Train Epoch: [97/100] \tLoss: 4.96 Test Loss: 30.33\n",
      "[2m 52s] Train Epoch: [98/100] \tLoss: 4.70 Test Loss: 30.33\n",
      "[2m 54s] Train Epoch: [99/100] \tLoss: 4.56 Test Loss: 30.33\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    # Iterate through the DataLoader\n",
    "    model.train()\n",
    "    for (sequences, labels, _) in train_loader:\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE)\n",
    "        \n",
    "        output = model(sequences)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    valid_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (sequences, labels, _) in test_loader:\n",
    "            sequences = sequences.squeeze(0).to(DEVICE)\n",
    "            labels = labels.squeeze(0).to(DEVICE)\n",
    "        \n",
    "            output = model(sequences)\n",
    "        \n",
    "            loss = criterion(output, labels)\n",
    "            valid_loss += loss.item()\n",
    "        \n",
    "    print('[{}] Train Epoch: [{}/{}] \\tLoss: {:.2f} Test Loss: {:.2f}'.format(\n",
    "            time_since(start), epoch, EPOCHS,\n",
    "            total_loss, valid_loss*len(train_loader)/len(test_loader)))\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models_icdc\\\\gru.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.96%\n",
      "Test Accuracy: 96.56%\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: {:.2f}%'.format(accuracy(model, train_loader)))\n",
    "print('Test Accuracy: {:.2f}%'.format(accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB # best\n",
    "from sklearn.svm import SVC # best\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "for (_, labels, real) in train_loader:\n",
    "    X_train += [i[0] for i in real]\n",
    "    y_train += labels.squeeze(0).argmax(dim=1).numpy().tolist()\n",
    "    \n",
    "X_test, y_test = [], []\n",
    "for (_, labels, real) in test_loader:\n",
    "    X_test += [i[0] for i in real]\n",
    "    y_test += labels.squeeze(0).argmax(dim=1).numpy().tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "with open('models_icdc\\\\vectorizer.states.pkl','rb') as f: \n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('models_icdc\\\\vectorizer.states.pkl','wb') as f: pickle.dump(vectorizer,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9679555084745762\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\lr.model.pkl', 'rb') as f:\n",
    "    lr_classifier = pickle.load(f)\n",
    "pred_lr = lr_classifier.predict(X_test_vect)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_classifier.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=300)\n",
    "lr_classifier.fit(X_train_vect, y_train)\n",
    "pred_lr = lr_classifier.predict(X_test_vect)\n",
    "\n",
    "with open('models_icdc\\\\lr.model.pkl','wb') as f: pickle.dump(lr_classifier,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9769597457627118\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\nb.model.pkl', 'rb') as f:\n",
    "    nb_classifier = pickle.load(f)\n",
    "pred_nb = nb_classifier.predict(X_test_vect)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_classifier.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9769597457627118\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vect, y_train)\n",
    "pred_nb = nb_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\nb.model.pkl','wb') as f: pickle.dump(nb_classifier,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier F1 score:  0.9245796017973961\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\rf.model.pkl', 'rb') as f:\n",
    "    rf_classifier = pickle.load(f)\n",
    "pred_rf = rf_classifier.predict(X_test_vect)\n",
    "print(\"RandomForestClassifier F1 score: \", f1_score(y_test, rf_classifier.predict(X_test_vect), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier F1 score:  0.9245796017973961\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_vect, y_train)\n",
    "pred_rf = rf_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\rf.model.pkl','wb') as f: pickle.dump(rf_classifier,f)\n",
    "print(\"RandomForestClassifier F1 score: \", f1_score(y_test, pred_rf, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier F1 score:  0.9020493021687092\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\xgb.model.pkl', 'rb') as f:\n",
    "    xgb_classifier = pickle.load(f)\n",
    "pred_xgb = xgb_classifier.predict(X_test_vect)\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, xgb_classifier.predict(X_test_vect), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier F1 score:  0.9020493021687092\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train_vect, y_train)\n",
    "pred_xgb = xgb_classifier.predict(X_test_vect)\n",
    "with open('models_icdc\\\\xgb.model.pkl','wb') as f: pickle.dump(xgb_classifier,f)\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, pred_xgb, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9690148305084746\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\svm.model.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)\n",
    "pred_SVM = svm_model.predict(X_test_vect)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_model.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9690148305084746\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train_vect, y_train)\n",
    "pred_SVM = svm_model.predict(X_test_vect)\n",
    "with open('models_icdc\\\\svm.model.pkl','wb') as f: pickle.dump(svm_model,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848781779661017\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('models_icdc\\\\dtc.model.pkl', 'rb') as f:\n",
    "    DTC = pickle.load(f)\n",
    "pred_DTC=DTC.predict(X_test_vect)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, DTC.predict(X_test_vect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848781779661017\n"
     ]
    }
   ],
   "source": [
    "DTC=DecisionTreeClassifier()\n",
    "DTC.fit(X_train_vect,y_train)\n",
    "pred_DTC=DTC.predict(X_test_vect)\n",
    "with open('models_icdc\\\\dtc.model.pkl','wb') as f: pickle.dump(DTC,f)\n",
    "print(\"Accuracy:\", accuracy_score(y_test,pred_DTC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "model.eval()\n",
    "test_gru = []\n",
    "pred_gru = []\n",
    "with torch.no_grad():    \n",
    "    for (sequences, labels, _) in test_loader: # test_loader\n",
    "        sequences = sequences.squeeze(0).to(DEVICE)\n",
    "        labels = labels.squeeze(0).to(DEVICE).argmax(dim=1)\n",
    "        # Forward pass\n",
    "        predicted = model(sequences).argmax(dim=1)\n",
    "        test_gru.append(labels.cpu().numpy())\n",
    "        pred_gru.append(predicted.cpu().numpy())\n",
    "model.train()\n",
    "test_gru = np.concatenate(test_gru, axis = 0)\n",
    "pred_gru = np.concatenate(pred_gru, axis = 0)\n",
    "\n",
    "\n",
    "def model_predict(X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs =  model(preprocesser(X).to(DEVICE)).cpu().numpy()\n",
    "    model.train()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 score:  0.9680349579067693\n",
      "Naive Bayes F1 score:  0.9767645507998631\n",
      "SVM F1 score:  0.9691697667143868\n",
      "Decission Tree Classifier F1 score:  0.8520085722918403\n",
      "GRU F1 score:  0.9656513890863466\n",
      "\n",
      "Logistic Regression Accuracy:  0.9679555084745762\n",
      "Naive Bayes Accuracy:  0.9769597457627118\n",
      "SVM Accuracy:  0.9690148305084746\n",
      "Decission Tree Classifier Accuracy:  0.848781779661017\n",
      "GRU Accuracy:  0.965572033898305\n",
      "\n",
      "Logistic Regression MSE:  0.816207627118644\n",
      "Naive Bayes MSE:  0.5238347457627118\n",
      "SVM MSE:  0.7915783898305084\n",
      "Decission Tree Classifier MSE:  4.112023305084746\n",
      "GRU MSE:  0.8442796610169492\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression F1 score: \", f1_score(y_test, pred_lr,average='weighted'))\n",
    "print(\"Naive Bayes F1 score: \", f1_score(y_test, pred_nb,average='weighted'))\n",
    "print(\"SVM F1 score: \", f1_score(y_test, pred_SVM,average='weighted'))\n",
    "print(\"Decission Tree Classifier F1 score: \",f1_score(y_test, pred_DTC,average='weighted'))\n",
    "print(\"GRU F1 score: \", f1_score(test_gru, pred_gru,average='weighted'))\n",
    "print()\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_test, pred_lr))\n",
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, pred_nb))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier Accuracy: \",accuracy_score(y_test, pred_DTC))\n",
    "print(\"GRU Accuracy: \", accuracy_score(test_gru, pred_gru))\n",
    "print()\n",
    "print(\"Logistic Regression MSE: \", mean_squared_error(y_test, pred_lr))\n",
    "print(\"Naive Bayes MSE: \", mean_squared_error(y_test, pred_nb))\n",
    "print(\"SVM MSE: \", mean_squared_error(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier MSE: \",mean_squared_error(y_test, pred_DTC))\n",
    "print(\"GRU MSE: \", mean_squared_error(test_gru, pred_gru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE and MAKE between 0 and 1\n",
    "def prob(arr:np.ndarray, gap_adjuster:int=3)->np.ndarray:\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = (arr-arr.min())/(arr.max()-arr.min())\n",
    "        if gap_adjuster!=1: arr = arr**gap_adjuster\n",
    "        return arr/arr.sum()\n",
    "    else:\n",
    "        arr = (arr-arr.min(axis=1).reshape(-1, 1))/(arr.max(axis=1)-arr.min(axis=1)).reshape(-1, 1)\n",
    "        if gap_adjuster!=1: arr = arr**gap_adjuster\n",
    "        return arr/arr.sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0020 0.0058 0.0000',\n",
       " '0.0018 0.0057 0.0000',\n",
       " '0.9682 0.8851 1.0000',\n",
       " '0.0022 0.0036 0.0000',\n",
       " '0.0028 0.0047 0.0000',\n",
       " '0.0028 0.0064 0.0000',\n",
       " '0.0013 0.0054 0.0000',\n",
       " '0.0026 0.0048 0.0000',\n",
       " '0.0043 0.0067 0.0000',\n",
       " '0.0093 0.0609 0.0000',\n",
       " '0.0025 0.0108 0.0000']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{:.4f} {:.4f} {:.4f}\".format(i1, i2, i3) for i1, i2, i3 in zip(\n",
    "        lr_classifier.predict_proba(X_test_vect[:1])[0], \n",
    "        nb_classifier.predict_proba(X_test_vect[:1])[0],\n",
    "        svm_model.predict_proba(X_test_vect[:1])[0]\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tmp = model(sequences).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0000 -5.5980',\n",
       " '0.0027 -2.5017',\n",
       " '0.0001 -4.5728',\n",
       " '0.0104 -0.7229',\n",
       " '0.0281 1.1952',\n",
       " '0.0012 -3.2496',\n",
       " '0.0006 -3.6695',\n",
       " '0.9169 16.1029',\n",
       " '0.0086 -1.0236',\n",
       " '0.0061 -1.5134',\n",
       " '0.0253 0.9629']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{:.4f} {:.4f}\".format(i1, i2) for i1, i2 in zip(prob(tmp[0]).tolist(), tmp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emsemble_infer_v1(texts:str|list[str], printable=False):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    output = (\n",
    "        lr_classifier.predict_proba(vectorizer.transform(texts)) +\n",
    "        nb_classifier.predict_proba(vectorizer.transform(texts)) + \n",
    "        svm_model.predict_proba(vectorizer.transform(texts)) + \n",
    "        prob(model_predict(texts))\n",
    "    ).argmax(axis=1)\n",
    "    if printable:\n",
    "        return [['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][i] for i in output.tolist()]\n",
    "    else:\n",
    "        return output\n",
    "    \n",
    "    \n",
    "emsemble_infer_v1('alute masala makhie, fetano basena chubie nie dubo tele bhaja yatakshan na bhalo kare bhaja hachche, tiri kara has maharashtrer ei suswadu o janapriya khavarer pad.', \n",
    "                  printable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9870164293079388\n",
      "Accuracy:  0.9870233050847458\n",
      "MSE:  0.4059851694915254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_emsemble_v1 = []\n",
    "for i in tqdm(range(0, len(X_test), 64)):\n",
    "    pred_emsemble_v1.append(emsemble_infer_v1(X_test[i:i+64]))\n",
    "\n",
    "pred_emsemble_v1 = np.concatenate(pred_emsemble_v1, axis = 0)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v1,average='weighted'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v1))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emsemble_infer_v2(texts:str|list[str], printable=False):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    output = (\n",
    "        prob(lr_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        prob(nb_classifier.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        # prob(svm_model.predict_proba(vectorizer.transform(texts)), gap_adjuster=1) + \n",
    "        prob(model_predict(texts), gap_adjuster=6)\n",
    "    ).argmax(axis=1)\n",
    "    if printable:\n",
    "        return [['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][i] for i in output.tolist()]\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:01<00:00, 39.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9896687963030091\n",
      "Accuracy:  0.9896716101694916\n",
      "MSE:  0.3061440677966102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_emsemble_v2 = []\n",
    "for i in tqdm(range(0, len(X_test), 64)):\n",
    "    pred_emsemble_v2.append(emsemble_infer_v2(X_test[i:i+64]))\n",
    "\n",
    "pred_emsemble_v2 = np.concatenate(pred_emsemble_v2, axis = 0)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v2, average='weighted'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v2))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben', 'hin', 'eng']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emsemble_infer_v2([\"m mase kono ullekhayogya tapapravaher dasha anubhav kara yyani.\", 'tum kya kar rahe ho yaar?', 'can you do somethig for me?'], printable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ben']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emsemble_infer_v3_last(texts:str|list[str], printable=False, proba=False):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    output = (\n",
    "        lr_classifier.predict_proba(vectorizer.transform(texts)) +\n",
    "        nb_classifier.predict_proba(vectorizer.transform(texts)) +\n",
    "        prob(model_predict(texts), gap_adjuster=1)\n",
    "    )\n",
    "    if proba: \n",
    "        return output\n",
    "    if printable:\n",
    "        return [['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][i] for i in output.argmax(axis=1).tolist()]\n",
    "    else:\n",
    "        return output.argmax(axis=1)\n",
    "    \n",
    "    \n",
    "emsemble_infer_v3_last('alute masala makhie, fetano basena chubie nie dubo tele bhaja yatakshan na bhalo kare bhaja hachche, tiri kara has maharashtrer ei suswadu o janapriya khavarer pad.', \n",
    "                  printable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:01<00:00, 39.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9907243664756155\n",
      "Accuracy:  0.9907309322033898\n",
      "MSE:  0.3003177966101695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_emsemble_v3 = []\n",
    "for i in tqdm(range(0, len(X_test), 64)):\n",
    "    pred_emsemble_v3.append(emsemble_infer_v3_last(X_test[i:i+64]))\n",
    "\n",
    "pred_emsemble_v3 = np.concatenate(pred_emsemble_v3, axis = 0)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, pred_emsemble_v3,average='weighted'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_emsemble_v3))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred_emsemble_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(idx): return ['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: `urd` but model gives `hin`\n",
      "tum mushkil se padhaai karte ho.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "mujhe pichhali class main bataai gai kuch nadiyaan yaad hai.\n",
      "\n",
      "Error: `ori` but model gives `guj`\n",
      "tame kouthiki yaythil?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "aaj ke liye itanaa hi.\n",
      "\n",
      "Error: `pan` but model gives `urd`\n",
      "awchha, kallh 14 april hai hain naame?\n",
      "\n",
      "Error: `tel` but model gives `ori`\n",
      "i madhya evaina bike ridlaki valelava?\n",
      "\n",
      "Error: `mal` but model gives `tel`\n",
      "mashru broun riso chican kuino birianio polayullav.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "aap jis dish kii baat kar rahi hai, use peetha yaa kholaa peetha kehete hai.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "compozit package main is sab ke saath jaigarh or royal senotafa shaamil hai.\n",
      "\n",
      "Error: `mal` but model gives `tel`\n",
      "sindagi na milengi dobara, del chahta hai ocaillae entu road trippa?\n",
      "\n",
      "Error: `mal` but model gives `kan`\n",
      "ill, avarentin buddhimutant?\n",
      "\n",
      "Error: `guj` but model gives `tam`\n",
      "baas, tyano anand man.\n",
      "\n",
      "Error: `guj` but model gives `ben`\n",
      "suprabhat, kumari lia!\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "hai naman! main rahul.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "tum kaise ho?\n",
      "\n",
      "Error: `urd` but model gives `pan`\n",
      "oh, thik hai.\n",
      "\n",
      "Error: `urd` but model gives `pan`\n",
      "bilkul madam.\n",
      "\n",
      "Error: `kan` but model gives `ben`\n",
      "goa, maccha!!!\n",
      "\n",
      "Error: `mal` but model gives `kan`\n",
      "parade tuirio?\n",
      "\n",
      "Error: `ori` but model gives `guj`\n",
      "aa' o basipad.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "main paisa nikaalane ke baad khate main bachi rakam kaise jaan saktaa hum?\n",
      "\n",
      "Error: `tel` but model gives `ben`\n",
      "halo, trinity elementry skull art tichar raadhik garena?\n",
      "\n",
      "Error: `mal` but model gives `eng`\n",
      "halo, it jaipur city palacelle?\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "tum lavola college gaye the, hai naa?\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "is bhram ko hataane ke liye log aparigrah kii pratigya lete hai or aatma kii purnataa ko jaan pate hai.\n",
      "\n",
      "Error: `mal` but model gives `tel`\n",
      "shubhadinam, suhritte, artists galeriai swagata!\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "1960 ke olympic khelon main 400 meter kafainal?\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "film prashansa paathyakram kaa sheetakaaleen sanskaran 23 november 2020 ko prarambh kiya gaya tha.\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "kshetreey gridon kaa pratham antaryojan aktubar 1991 main sthapit kiya gaya tha jab uttar-poorviy or poorviy gridon ko antaryojit kiya gaya tha.\n",
      "\n",
      "Error: `guj` but model gives `ben`\n",
      "card pahochadwama ketlo samay lagfee?\n",
      "\n",
      "Error: `hin` but model gives `urd`\n",
      "2000 main, dramvadak denis chembers (carlos santana, jon mcloclin, or anya), ke saath usne rescue record kiya, or 2006 main deje logic or keller williams (guitar or baas) ke saath shato banaras kaa vimochan kiya.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "vahaan bas lutf induz ho.\n",
      "\n",
      "Error: `eng` but model gives `mal`\n",
      "Stay back at home, relax.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "mujhe wo son pari main bahut pasand thi.\n",
      "\n",
      "Error: `urd` but model gives `hin`\n",
      "haan, or puri parade main meraa pasandida hissaa bhi.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp, real, pred in zip(X_test, y_test, pred_emsemble_v3):\n",
    "    if real != pred:\n",
    "        # if get_class(real) not in ['hin', 'urd'] and get_class(pred) not in ['hin', 'urd']:\n",
    "        print(f\"Error: `{get_class(real)}` but model gives `{get_class(pred)}`\")\n",
    "        print(inp)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.08851273813616918, 'ben'),\n",
       " (0.15902469111992074, 'guj'),\n",
       " (0.11512846096708404, 'hin'),\n",
       " (1.5802366012509674, 'kan'),\n",
       " (0.20267497443752558, 'mal'),\n",
       " (0.17614189506499442, 'ori'),\n",
       " (0.05903100059979048, 'pan'),\n",
       " (0.21048618463086474, 'tam'),\n",
       " (0.18335848900092241, 'tel'),\n",
       " (0.10543904256506387, 'urd'),\n",
       " (0.11996591850140624, 'eng')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, j) for i, j in zip(emsemble_infer_v3_last(\"Naanu indhu Kannadadalli neevu yava sahaya vanavu bekaadaru neeDabahudu. Neenu nannaNNu yavudu keLidaru naanu nimge sahaya maadutteene.\", proba=True)[0], ['ben', 'guj', 'hin', 'kan', 'mal', 'ori', 'pan', 'tam', 'tel', 'urd', 'eng'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 score:  0.9680349579067693\n",
      "Naive Bayes F1 score:  0.9767645507998631\n",
      "SVM F1 score:  0.9691697667143868\n",
      "Decission Tree Classifier F1 score:  0.8520085722918403\n",
      "XGBClassifier F1 score:  0.9020493021687092\n",
      "LSTM F1 score:  0.9656513890863466\n",
      "\n",
      "Logistic Regression Accuracy:  0.9679555084745762\n",
      "Naive Bayes Accuracy:  0.9769597457627118\n",
      "SVM Accuracy:  0.9690148305084746\n",
      "Decission Tree Classifier Accuracy:  0.848781779661017\n",
      "XGBClassifier F1 score:  0.897510593220339\n",
      "LSTM Accuracy:  0.965572033898305\n",
      "\n",
      "Logistic Regression MSE:  0.816207627118644\n",
      "Naive Bayes MSE:  0.5238347457627118\n",
      "SVM MSE:  0.7915783898305084\n",
      "Decission Tree Classifier MSE:  4.112023305084746\n",
      "XGBClassifier MSE:  2.220074152542373\n",
      "LSTM MSE:  0.8442796610169492\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression F1 score: \", f1_score(y_test, pred_lr,average='weighted'))\n",
    "print(\"Naive Bayes F1 score: \", f1_score(y_test, pred_nb,average='weighted'))\n",
    "print(\"SVM F1 score: \", f1_score(y_test, pred_SVM,average='weighted'))\n",
    "print(\"Decission Tree Classifier F1 score: \",f1_score(y_test, pred_DTC,average='weighted'))\n",
    "print(\"XGBClassifier F1 score: \", f1_score(y_test, pred_xgb, average='weighted'))\n",
    "print(\"LSTM F1 score: \", f1_score(test_gru, pred_gru,average='weighted'))\n",
    "print()\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_test, pred_lr))\n",
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, pred_nb))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier Accuracy: \",accuracy_score(y_test, pred_DTC))\n",
    "print(\"XGBClassifier F1 score: \", accuracy_score(y_test, pred_xgb))\n",
    "print(\"LSTM Accuracy: \", accuracy_score(test_gru, pred_gru))\n",
    "print()\n",
    "print(\"Logistic Regression MSE: \", mean_squared_error(y_test, pred_lr))\n",
    "print(\"Naive Bayes MSE: \", mean_squared_error(y_test, pred_nb))\n",
    "print(\"SVM MSE: \", mean_squared_error(y_test, pred_SVM))\n",
    "print(\"Decission Tree Classifier MSE: \",mean_squared_error(y_test, pred_DTC))\n",
    "print(\"XGBClassifier MSE: \", mean_squared_error(y_test, pred_xgb))\n",
    "print(\"LSTM MSE: \", mean_squared_error(test_gru, pred_gru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 = (SVM + LR + NV + LSTM)\n",
      "emsemble_v1 F1 score:  0.9870164293079388\n",
      "emsemble_v1 Accuracy:  0.9870233050847458\n",
      "emsemble_v1 MSE:  0.4059851694915254\n",
      "v2 = (LR + NV + LSTM)\n",
      "emsemble_v2 F1 score:  0.9896687963030091\n",
      "emsemble_v2 Accuracy:  0.9896716101694916\n",
      "emsemble_v2 MSE:  0.3061440677966102\n",
      "v3 = (LR + NV + LSTM)\n",
      "emsemble_v3 F1 score:  0.9907243664756155\n",
      "emsemble_v3 Accuracy:  0.9907309322033898\n",
      "emsemble_v3 MSE:  0.3003177966101695\n"
     ]
    }
   ],
   "source": [
    "print(\"v1 = (SVM + LR + NV + LSTM)\")\n",
    "print(\"emsemble_v1 F1 score: \", f1_score(y_test, pred_emsemble_v1, average='weighted'))\n",
    "print(\"emsemble_v1 Accuracy: \", accuracy_score(y_test, pred_emsemble_v1))\n",
    "print(\"emsemble_v1 MSE: \", mean_squared_error(y_test, pred_emsemble_v1))\n",
    "print(\"v2 = (LR + NV + LSTM)\")\n",
    "print(\"emsemble_v2 F1 score: \", f1_score(y_test, pred_emsemble_v2, average='weighted'))\n",
    "print(\"emsemble_v2 Accuracy: \", accuracy_score(y_test, pred_emsemble_v2))\n",
    "print(\"emsemble_v2 MSE: \", mean_squared_error(y_test, pred_emsemble_v2))\n",
    "print(\"v3 = (LR + NV + LSTM)\")\n",
    "print(\"emsemble_v3 F1 score: \", f1_score(y_test, pred_emsemble_v3,average='weighted'))\n",
    "print(\"emsemble_v3 Accuracy: \", accuracy_score(y_test, pred_emsemble_v3))\n",
    "print(\"emsemble_v3 MSE: \", mean_squared_error(y_test, pred_emsemble_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
